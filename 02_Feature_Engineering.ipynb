{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Costa Rican Household Poverty Level Prediction\n",
    "*From Kaggle ([competition link](https://www.kaggle.com/c/costa-rican-household-poverty-prediction))*\n",
    "  \n",
    "**By Nema Sobhani & David LaCharite**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Income qualification for poor families in Costa Rica to determing need for aid. Data gathered from the *Inter-American Development Bank.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Functions\n",
    "from functions import *\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "from pprint import pprint\n",
    "\n",
    "# Classification\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rent Prediction\n",
    "\n",
    "We decided to use regression models to predict **rent** as an approach to filling missing values to increase our power in predicting **poverty level**.  \n",
    "\n",
    "\n",
    "After testing with tree-style classifiers (Random Forrest, XGBoost) and linear models (Linear Regression, RidgeCV, LassoCV, ElasticNetCV), we found that **Random Forest Regression** gave the highest scores in predicting rent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up new dataframe (including rent data)\n",
    "df_rent = dataframe_generator('train.csv', rent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values of explanatory variables: 0\n",
      "Missing values of target variable (rent): 6860\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values of explanatory variables:\", df_rent.drop(columns='v2a1').isna().sum().sum())\n",
    "print(\"Missing values of target variable (rent):\", df_rent.v2a1.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rent Prediction Function\n",
    "def dataframe_generator_rent(data):\n",
    "    \n",
    "    #_______________________________\n",
    "    # DATAFRAME SETUP\n",
    "    #_______________________________\n",
    "    \n",
    "    # Setting up new dataframe (including rent data)\n",
    "    df_rent = dataframe_generator(data, rent=True)\n",
    "    \n",
    "    # Remove missing values for target (rent)\n",
    "    df_rent_predict = df_rent.dropna()\n",
    "\n",
    "    \n",
    "    #_______________________________\n",
    "    # CLASSIFICATION SETUP\n",
    "    #_______________________________\n",
    "    \n",
    "    # Partition explanatory and response variables\n",
    "    X = df_rent_predict.drop(columns=['v2a1', 'Id', 'idhogar'])\n",
    "    y = df_rent_predict['v2a1']\n",
    "\n",
    "    # Split into training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=12345)\n",
    "    \n",
    "    \n",
    "    #_______________________________\n",
    "    # CLASSIFICATION \n",
    "    # (using random forest because it consistently gave highest score)\n",
    "    #_______________________________\n",
    "    \n",
    "    # XGB\n",
    "    # clf = xgb.XGBClassifier(max_depth=6,n_estimators=100, n_jobs=-1, subsample=.7)\n",
    "    # clf.fit(X_train, y_train)\n",
    "    # print(clf.score(X_test, y_test))\n",
    "    \n",
    "    # Random Forest\n",
    "    clf = RandomForestRegressor()\n",
    "    clf.fit(X_train, y_train)\n",
    "    # print(clf.score(X_test, y_test))\n",
    "    \n",
    "    \n",
    "    #_______________________________\n",
    "    # FILL NAN USING PREDICTED VALUES FROM MODEL\n",
    "    #_______________________________\n",
    "    \n",
    "    # Prepare data to fill in predicted values for rent\n",
    "    df_rent_nan = df_rent[df_rent.v2a1.isna()]\n",
    "    \n",
    "    # Predict using model\n",
    "    rent_pred = clf.predict(df_rent_nan.drop(columns=['v2a1', 'Id', 'idhogar']))\n",
    "    \n",
    "    # Fill NaN\n",
    "    df_rent_nan['v2a1'] = pd.DataFrame(rent_pred).values\n",
    "    \n",
    "    # Update full dataframe\n",
    "    df_rent[df_rent.v2a1.isna()] = df_rent_nan\n",
    "    \n",
    "    \n",
    "    return df_rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemosaic/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_rent = dataframe_generator_rent('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rent.to_pickle(\"df_rent.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations\n",
    "\n",
    "We will take random subsets of the top 8 variables (determined from classification on full model without rent), along with their square and log transformations and see if any result in better scoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up list of variable names including untransformed, squares, and logs\n",
    "top_features = ['v2a1', 'meaneduc', 'SQBedjefe', 'overcrowding', 'SQBdependency', 'age', 'rooms', 'qmobilephone']\n",
    "top_features_SQ = [\"SQ_\" + i for i in top_features]\n",
    "top_features_LOG = [\"LOG_\" + i for i in top_features]\n",
    "\n",
    "top_features_master = top_features + top_features_SQ + top_features_LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running best_subset simulations of sample size:\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['SQBedjefe',\n",
       "  'SQ_SQBedjefe',\n",
       "  'LOG_meaneduc',\n",
       "  'v2a1',\n",
       "  'LOG_overcrowding',\n",
       "  'LOG_v2a1',\n",
       "  'LOG_rooms',\n",
       "  'LOG_SQBdependency',\n",
       "  'rooms',\n",
       "  'SQ_qmobilephone',\n",
       "  'SQ_v2a1',\n",
       "  'LOG_age',\n",
       "  'meaneduc',\n",
       "  'age',\n",
       "  'SQ_age',\n",
       "  'SQBdependency',\n",
       "  'SQ_SQBdependency'],\n",
       " 17,\n",
       " 0.9100418410041841,\n",
       " 0.8665894529811344]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking random subsets of varying sizes and running classifier to determine best subset\n",
    "import random\n",
    "random.seed(12345)\n",
    "\n",
    "best_subset = None\n",
    "\n",
    "# Iterate to find best feature subset and subset size\n",
    "print(\"Currently running best_subset simulations of sample size:\")\n",
    "for size in range(8, 25):\n",
    "    print(size)\n",
    "    for run in range(10): # Scale up to 100, 1000, 10000, etc depending on computational power\n",
    "        \n",
    "        # Make copy of dataframe and remove original top 8 features\n",
    "        df_test = df_rent.copy(deep=True)\n",
    "        df_test.drop(columns=top_features, inplace=True)\n",
    "        \n",
    "        # Randomly sample subset without replacement\n",
    "        subset = random.sample(top_features_master, size)\n",
    "        \n",
    "        # Add columns to dataframe\n",
    "        for feature in subset:\n",
    "            if \"SQ_\" in feature:\n",
    "                col = feature.split(\"SQ_\")[1]\n",
    "                df_test[col] = df_rent[col] ** 2\n",
    "                \n",
    "            elif \"LOG_\" in feature:\n",
    "                col = feature.split(\"LOG_\")[1]\n",
    "                df_test[col] = df_rent[col].apply(lambda x: np.log(x) if x!=0 else x)\n",
    "                \n",
    "            else:\n",
    "                col = feature\n",
    "                df_test[col] = df_rent[col]\n",
    "            \n",
    "        # Run model in Random Forest\n",
    "        X = df_test.drop(columns=['Target', 'Id', 'idhogar'])\n",
    "        y = df_test['Target']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state=12345)\n",
    "        \n",
    "        clf_RF = RandomForestClassifier(n_estimators=10)\n",
    "        clf_RF.fit(X_train, y_train)\n",
    "        \n",
    "        score = clf_RF.score(X_test, y_test)\n",
    "        y_pred = clf_RF.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "        if best_subset:\n",
    "            if f1 > best_subset[3]:\n",
    "                best_subset = [subset, size, score, f1]\n",
    "        else:\n",
    "            best_subset = [subset, size, score, f1]\n",
    "        \n",
    "best_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TOO COMPUTATIONALLY EXPENSIVE\n",
    "# # Trying all combinations of varying sizes and running classifier to determine best subset\n",
    "# from itertools import combinations\n",
    "\n",
    "# best_subset = None\n",
    "\n",
    "# # Iterate to find best feature subset and subset size\n",
    "# print(\"Currently running best_subset simulations of sample size:\")\n",
    "\n",
    "# for size in range(8, 21):\n",
    "    \n",
    "# #     print(size)\n",
    "    \n",
    "#     # Combinations to try\n",
    "#     comb = list(combinations(top_features_master, size))\n",
    "    \n",
    "#     for run in range(len(comb)):\n",
    "    \n",
    "#         # Status Update\n",
    "#         if len(comb) % (run+1) == 0:\n",
    "#             print(f'Size {size}: {(run+1) / len(comb) * 100:.5f}%')\n",
    "            \n",
    "#         # Subset\n",
    "#         subset = comb[run]\n",
    "        \n",
    "#         # Make copy of dataframe and remove original top 8 features\n",
    "#         df_test = df_rent.copy(deep=True)\n",
    "#         df_test.drop(columns=top_features, inplace=True)\n",
    "        \n",
    "#         # Add columns to dataframe\n",
    "#         for feature in subset:\n",
    "#             if \"SQ_\" in feature:\n",
    "#                 col = feature.split(\"SQ_\")[1]\n",
    "#                 df_test[col] = df_rent[col] ** 2\n",
    "                \n",
    "#             elif \"LOG_\" in feature:\n",
    "#                 col = feature.split(\"LOG_\")[1]\n",
    "#                 df_test[col] = df_rent[col].apply(lambda x: np.log(x) if x!=0 else x)\n",
    "                \n",
    "#             else:\n",
    "#                 col = feature\n",
    "#                 df_test[col] = df_rent[col]\n",
    "            \n",
    "#         # Run model in Random Forest\n",
    "#         X = df_test.drop(columns='Target')\n",
    "#         y = df_test['Target']\n",
    "        \n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state=12345)\n",
    "        \n",
    "#         clf_RF = RandomForestClassifier(n_estimators=10)\n",
    "#         clf_RF.fit(X_train, y_train)\n",
    "        \n",
    "#         score = clf_RF.score(X_test, y_test)\n",
    "#         y_pred = clf_RF.predict(X_test)\n",
    "#         f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "#         if best_subset:\n",
    "#             if f1 > best_subset[3]:\n",
    "#                 best_subset = [subset, size, score, f1]\n",
    "#         else:\n",
    "#             best_subset = [subset, size, score, f1]\n",
    "        \n",
    "# best_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New DataFrame for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformed DataFrame Generator\n",
    "def dataframe_generator_trans(data):\n",
    "    \n",
    "    # Top Features\n",
    "    top_features = ['v2a1', 'meaneduc', 'SQBedjefe', 'overcrowding', 'SQBdependency', 'age', 'rooms', 'qmobilephone']\n",
    "\n",
    "    # Best subset\n",
    "    winner = \\\n",
    "            [['SQ_SQBedjefe',\n",
    "              'LOG_qmobilephone',\n",
    "              'SQ_v2a1',\n",
    "              'SQBdependency',\n",
    "              'SQBedjefe',\n",
    "              'meaneduc',\n",
    "              'qmobilephone',\n",
    "              'rooms',\n",
    "              'LOG_meaneduc',\n",
    "              'SQ_qmobilephone',\n",
    "              'v2a1',\n",
    "              'SQ_overcrowding',\n",
    "              'LOG_SQBdependency'],\n",
    "             13,\n",
    "             0.9257322175732218,\n",
    "             0.8887133182436542]\n",
    "            \n",
    "    # Create rent-inclusive dataframe\n",
    "    df_rent = dataframe_generator_rent(data)\n",
    "    \n",
    "    # Create transformed dataframe\n",
    "    df_trans = df_rent.copy(deep=True)\n",
    "    df_trans.drop(columns=top_features, inplace=True)\n",
    "\n",
    "    for feature in winner[0]:\n",
    "        if \"SQ_\" in feature:\n",
    "            col = feature.split(\"SQ_\")[1]\n",
    "            df_trans[feature] = df_rent[col] ** 2\n",
    "\n",
    "        elif \"LOG_\" in feature:\n",
    "            col = feature.split(\"LOG_\")[1]\n",
    "            df_trans[feature] = df_rent[col].apply(lambda x: np.log(x) if x!=0 else x)\n",
    "\n",
    "        else:\n",
    "            col = feature\n",
    "            df_trans[feature] = df_rent[col]\n",
    "            \n",
    "    return df_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemosaic/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_trans = dataframe_generator_trans(\"train.csv\")\n",
    "df_trans.to_pickle(\"df_trans.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
